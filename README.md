ğŸµ Music Genre Classification using Classical Machine Learning

From raw audio â†’ feature engineering â†’ models from scratch â†’ deep analysis

ğŸ” Overview

This project focuses on music genre classification using classical machine learning techniques.
The goal was to deeply understand the full ML pipeline, starting from raw audio processing to model implementation from scratch and thorough performance analysis.

ğŸ¯ Objective

Given an audio file, predict its music genre by extracting meaningful features and training machine learning models.

ğŸ”„ End-to-End Pipeline
Audio Files
   â†“
Feature Extraction
   â†“
Data Standardization & PCA
   â†“
Model Training (from scratch & sklearn)
   â†“
Evaluation & Visualization

ğŸ¼ Feature Extraction

Audio files were converted into structured numerical representations using:

MFCCs (Mel-Frequency Cepstral Coefficients)

Chroma features

Spectral Centroid

Spectral Bandwidth

Zero-Crossing Rate

Tempo-related features

These features capture both frequency and temporal characteristics of music.

ğŸ§  Models Implemented
ğŸ”¹ Logistic Regression (From Scratch)

Implemented using NumPy

Manual:

Loss computation

Gradient descent

Weight updates

Served as a baseline to understand optimization mechanics

ğŸ”¹ Scikit-learn Models

Logistic Regression

Random Forest

Support Vector Machine (SVM)

Gaussian Naive Bayes

Used to compare learning behavior, biasâ€“variance tradeoff, and performance.

âš™ï¸ Data Preprocessing

Trainâ€“test split

Feature standardization

Dimensionality reduction using PCA

Reduced noise and improved generalization

ğŸ“Š Evaluation Metrics

Models were evaluated using:

Accuracy

Precision

Recall

F1-score

Confusion Matrix

ğŸ“ˆ Visualization & Analysis

Training loss curves

Confusion matrices (heatmaps)

t-SNE visualization for feature separability

PCA variance analysis

These visualizations helped interpret model decision boundaries and data structure.

ğŸ” Key Learnings

Feature quality strongly impacts classical ML performance

PCA improves training stability and efficiency

Ensemble models (Random Forest) outperform linear models

SVM shows strong performance on high-dimensional data

Visualization is critical for interpretability

ğŸ› ï¸ Tech Stack

Python

NumPy

Scikit-learn

Librosa

Matplotlib

Seaborn

ğŸ“ Repository Structure
â”œâ”€â”€ data/
â”œâ”€â”€ feature_extraction/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_regression_from_scratch.py
â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”œâ”€â”€ svm.py
â”‚   â””â”€â”€ naive_bayes.py
â”œâ”€â”€ evaluation/
â”œâ”€â”€ visualization/
â””â”€â”€ README.md